{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  tf.experimental.numpy.random.seed(seed)\n",
    "\n",
    "set_seed()\n",
    "project_dir = os.getcwd()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_mn2 = keras.applications.MobileNetV2(\n",
    "    input_shape=None, alpha=1.0, include_top=True, weights='imagenet',\n",
    "    input_tensor=None, pooling=None, classes=1000\n",
    ")\n",
    "layer_name = 'block_15_add'\n",
    "feature_extractor = keras.models.Model(inputs=model_mn2.input, outputs=model_mn2.get_layer(layer_name).output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "models_path = os.path.join(project_dir, 'models')\n",
    "model_mobilenetv2_regularized = tf.keras.models.load_model(os.path.join(models_path, 'model_mobilenetv2_regularized_plantdoc'))\n",
    "model_squeeze_excite_resnet = tf.keras.models.load_model(os.path.join(models_path, 'model_squeeze_excite_resnet_plantdoc'))\n",
    "model_pca_based = tf.keras.models.load_model(os.path.join(models_path, 'model_pca_based_plantdoc'))\n",
    "model_pca_based_sepconv = tf.keras.models.load_model(os.path.join(models_path, 'model_pca_based_sepconv_plantdoc'))\n",
    "model_lda_based = tf.keras.models.load_model(os.path.join(models_path, 'model_lda_based_plantdoc'))\n",
    "model_lda_based_sepconv = tf.keras.models.load_model(os.path.join(models_path, 'model_lda_based_sepconv_plantdoc'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "diseases_names = []\n",
    "dataset_path = os.path.join(project_dir, 'datasets', 'encoded', 'PlantVillage')\n",
    "\n",
    "for diseases in os.listdir(os.path.join(dataset_path, 'train')):\n",
    "    diseases_names += [diseases.split('.npy')[0]]\n",
    "\n",
    "diseases_names.sort()\n",
    "plant_name_to_id = {plant: i for i, plant in enumerate(diseases_names)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26] val/Tomato Septoria leaf spot.npyyyy"
     ]
    }
   ],
   "source": [
    "instances = {}\n",
    "labels = {}\n",
    "\n",
    "for set_kind in [\"test\", \"train\", \"val\"]:\n",
    "    X_per_class = []\n",
    "    y_per_class = []\n",
    "\n",
    "    for i, file in enumerate(os.listdir(os.path.join(dataset_path, set_kind))):\n",
    "        print(f\"\\r[{i}] {set_kind}/{file}\", end='')\n",
    "        plants_encoded = np.load(os.path.join(dataset_path, set_kind, file))\n",
    "        plant_name = file.split('.npy')[0]\n",
    "\n",
    "        X_per_class += [plants_encoded.reshape([plants_encoded.shape[0], 49, 160])]\n",
    "        y_per_class += [plant_name_to_id[plant_name] for _ in range(plants_encoded.shape[0])]\n",
    "\n",
    "    instances[set_kind] = np.concatenate(X_per_class)\n",
    "    labels[set_kind] = np.array(y_per_class)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "n_classes = len(diseases_names)\n",
    "\n",
    "X_train = instances['train']\n",
    "y_train = np.eye(n_classes)[labels['train']]\n",
    "\n",
    "\n",
    "X_valid = instances['val']\n",
    "y_valid = np.eye(n_classes)[labels['val']]\n",
    "\n",
    "X_test = instances['test']\n",
    "y_test = np.eye(n_classes)[labels['test']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class PCATransformer(keras.layers.Layer):\n",
    "    def __init__(self, means, components, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.all_means = tf.reshape(tf.transpose(means), [1, 49, 160])\n",
    "        self.all_components = tf.transpose(components, perm=[0, 2, 1])\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, X):\n",
    "        return tf.transpose(tf.map_fn(\n",
    "            lambda inp: inp[0] @ inp[1],\n",
    "            (tf.transpose(X - self.all_means, perm=[2, 0, 1]), self.all_components),\n",
    "            fn_output_signature=tf.TensorSpec(shape=[None, 5])\n",
    "        ), perm=[1, 2, 0])\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape((batch_input_shape[0], 5, 160))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"mean\": self.all_means.numpy(), \"components\": self.all_components.numpy()}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "pca_per_filter = [\n",
    "    PCA(n_components=5).fit(X_train[..., i])\n",
    "    for i in range(X_train.shape[-1])\n",
    "]\n",
    "\n",
    "all_means = np.array([filter.mean_ for filter in pca_per_filter])\n",
    "all_components = np.array([filter.components_ for filter in pca_per_filter])\n",
    "pca_transformation = PCATransformer(tf.constant(all_means), tf.constant(all_components))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_2 (Batc  (None, 5, 160)           640       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv1d (Separable  (None, 1, 320)           156320    \n",
      " Conv1D)                                                         \n",
      "                                                                 \n",
      " elu_2 (ELU)                 (None, 1, 320)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 320)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 320)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 320)              1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 320)               102400    \n",
      "                                                                 \n",
      " elu_3 (ELU)                 (None, 320)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 320)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 27)                8667      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,307\n",
      "Trainable params: 268,347\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lda_based_sepconv.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2334\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in os.listdir('./datasets/original/PlantDoc/test'):\n",
    "    count += len(os.listdir('./datasets/original/PlantDoc/train/' + i))\n",
    "\n",
    "print(count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}